"""
2-Step vs í†µí•© MILP ë°©ì‹ ì‹¤ì œ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from datetime import datetime

# ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules import (
    DataLoader, StoreTierSystem, SKUClassifier, 
    IntegratedOptimizer, ResultAnalyzer,
    ResultVisualizer, ExperimentManager
)
from modules.three_step_optimizer import ThreeStepOptimizer
from config import EXPERIMENT_SCENARIOS


class MethodComparisonExperiment:
    """3-Step vs í†µí•© MILP ë°©ì‹ì˜ ì‹¤ì œ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜"""
    
    def __init__(self, target_style='DWLG42044'):
        self.target_style = target_style
        self.comparison_results = {}
        
    def setup_experiment_data(self):
        """ì‹¤í—˜ìš© ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ“Š ì‹¤í—˜ìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # 1. ë°ì´í„° ë¡œë“œ
        data_loader = DataLoader()
        data_loader.load_data()
        data_loader.filter_by_style(self.target_style)
        data = data_loader.get_basic_data_structures()
        
        # 2. ë§¤ì¥ Tier ì‹œìŠ¤í…œ ì„¤ì •
        tier_system = StoreTierSystem()
        target_stores = tier_system.get_target_stores(data['stores'], self.target_style)
        store_allocation_limits = tier_system.create_store_allocation_limits(target_stores)
        
        # 3. SKU ë¶„ë¥˜
        sku_classifier = SKUClassifier(data_loader.df_sku_filtered)
        scarce_skus, abundant_skus = sku_classifier.classify_skus(data['A'], target_stores)
        
        return {
            'data': data,
            'data_loader': data_loader,
            'tier_system': tier_system,
            'target_stores': target_stores,
            'store_allocation_limits': store_allocation_limits,
            'scarce_skus': scarce_skus,
            'abundant_skus': abundant_skus
        }
    
    def run_integrated_milp_method(self, experiment_data, scenario_params):
        """í†µí•© MILP ë°©ì‹ ì‹¤í–‰"""
        print(f"\nğŸ”§ í†µí•© MILP ë°©ì‹ ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        
        # í†µí•© MILP ìµœì í™”
        integrated_optimizer = IntegratedOptimizer(self.target_style)
        
        optimization_result = integrated_optimizer.optimize_integrated(
            experiment_data['data'], 
            experiment_data['scarce_skus'], 
            experiment_data['abundant_skus'], 
            experiment_data['target_stores'],
            experiment_data['store_allocation_limits'], 
            experiment_data['data_loader'].df_sku_filtered,
            experiment_data['tier_system'], 
            scenario_params
        )
        
        total_time = time.time() - start_time
        
        if optimization_result['status'] == 'success':
            # ëª©ì í•¨ìˆ˜ ë¶„í•´ ë¶„ì„
            objective_breakdown = integrated_optimizer.get_objective_breakdown()
            
            return {
                'method': 'integrated_milp',
                'status': 'success',
                'total_time': total_time,
                'optimization_result': optimization_result,
                'objective_breakdown': objective_breakdown,
                'final_allocation': optimization_result['final_allocation']
            }
        else:
            return {
                'method': 'integrated_milp',
                'status': 'failed',
                'total_time': total_time,
                'error': optimization_result.get('problem_status', 'unknown')
            }
    
    def run_two_step_method(self, experiment_data, scenario_params):
        """2-Step ë°©ì‹ ì‹¤í–‰"""
        print(f"\nğŸ“Š 2-Step ë°©ì‹ ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        
        # 2-Step ìµœì í™”
        two_step_optimizer = TwoStepOptimizer(self.target_style)
        
        optimization_result = two_step_optimizer.optimize_two_step(
            experiment_data['data'], 
            experiment_data['scarce_skus'], 
            experiment_data['abundant_skus'], 
            experiment_data['target_stores'],
            experiment_data['store_allocation_limits'], 
            experiment_data['data_loader'].df_sku_filtered,
            experiment_data['tier_system'], 
            scenario_params
        )
        
        total_time = time.time() - start_time
        
        if optimization_result['status'] == 'success':
            # ë‹¨ê³„ë³„ ë¶„ì„
            step_analysis = two_step_optimizer.get_step_analysis()
            
            return {
                'method': '2_step',
                'status': 'success',
                'total_time': total_time,
                'optimization_result': optimization_result,
                'step_analysis': step_analysis,
                'final_allocation': optimization_result['final_allocation']
            }
        else:
            return {
                'method': '2_step',
                'status': 'failed',
                'total_time': total_time,
                'error': optimization_result.get('step', 'unknown')
            }
    
    def analyze_allocation_results(self, method_result, experiment_data):
        """ë°°ë¶„ ê²°ê³¼ ë¶„ì„"""
        if method_result['status'] != 'success':
            return None
        
        final_allocation = method_result['final_allocation']
        
        # ResultAnalyzerë¥¼ ì‚¬ìš©í•œ ìƒì„¸ ë¶„ì„
        analyzer = ResultAnalyzer(self.target_style)
        analysis_results = analyzer.analyze_results(
            final_allocation, 
            experiment_data['data'], 
            experiment_data['scarce_skus'], 
            experiment_data['abundant_skus'],
            experiment_data['target_stores'], 
            experiment_data['data_loader'].df_sku_filtered, 
            experiment_data['data']['QSUM'], 
            experiment_data['tier_system']
        )
        
        return analysis_results
    
    def compare_methods(self, scenario_name='baseline'):
        """ë‘ ë°©ì‹ ì§ì ‘ ë¹„êµ"""
        print(f"ğŸ† ë°©ì‹ë³„ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ ì‹œì‘")
        print(f"   ëŒ€ìƒ ìŠ¤íƒ€ì¼: {self.target_style}")
        print(f"   ì‹œë‚˜ë¦¬ì˜¤: {scenario_name}")
        print("="*60)
        
        # 1. ì‹¤í—˜ ë°ì´í„° ì¤€ë¹„
        experiment_data = self.setup_experiment_data()
        scenario_params = EXPERIMENT_SCENARIOS[scenario_name].copy()
        
        # 2. í†µí•© MILP ë°©ì‹ ì‹¤í–‰
        integrated_result = self.run_integrated_milp_method(experiment_data, scenario_params)
        integrated_analysis = self.analyze_allocation_results(integrated_result, experiment_data)
        
        # 3. 2-Step ë°©ì‹ ì‹¤í–‰
        two_step_result = self.run_two_step_method(experiment_data, scenario_params)
        two_step_analysis = self.analyze_allocation_results(two_step_result, experiment_data)
        
        # 4. ê²°ê³¼ ë¹„êµ ë¶„ì„
        comparison = self._create_detailed_comparison(
            integrated_result, integrated_analysis,
            two_step_result, two_step_analysis,
            scenario_params
        )
        
        # 5. ê²°ê³¼ ì¶œë ¥
        self._print_comparison_results(comparison)
        
        return comparison
    
    def _create_detailed_comparison(self, integrated_result, integrated_analysis,
                                  two_step_result, two_step_analysis, scenario_params):
        """ìƒì„¸ ë¹„êµ ë¶„ì„ ìƒì„±"""
        
        comparison = {
            'scenario': scenario_params,
            'timestamp': datetime.now(),
            'methods': {
                'integrated_milp': {
                    'result': integrated_result,
                    'analysis': integrated_analysis
                },
                '2_step': {
                    'result': two_step_result,
                    'analysis': two_step_analysis
                }
            }
        }
        
        # ì„±ê³µí•œ ë°©ì‹ë“¤ë§Œ ë¹„êµ
        if integrated_result['status'] == 'success' and two_step_result['status'] == 'success':
            
            # 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ
            comparison['performance_metrics'] = self._compare_performance_metrics(
                integrated_result, integrated_analysis,
                two_step_result, two_step_analysis
            )
            
            # 2. ê³„ì‚° íš¨ìœ¨ì„± ë¹„êµ
            comparison['computational_efficiency'] = self._compare_computational_efficiency(
                integrated_result, two_step_result
            )
            
            # 3. ì»¤ë²„ë¦¬ì§€ ë¹„êµ
            comparison['coverage_comparison'] = self._compare_coverage(
                integrated_analysis, two_step_analysis
            )
            
            # 4. ë°°ë¶„ íš¨ìœ¨ì„± ë¹„êµ
            comparison['allocation_efficiency'] = self._compare_allocation_efficiency(
                integrated_result, two_step_result
            )
            
            # 5. ì¢…í•© í‰ê°€
            comparison['overall_assessment'] = self._create_overall_assessment(comparison)
        
        return comparison
    
    def _compare_performance_metrics(self, integrated_result, integrated_analysis,
                                   two_step_result, two_step_analysis):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ"""
        
        int_eval = integrated_analysis['overall_evaluation']
        ts_eval = two_step_analysis['overall_evaluation']
        
        return {
            'color_coverage': {
                'integrated_milp': int_eval['overall_color_coverage'],
                '2_step': ts_eval['overall_color_coverage'],
                'winner': 'integrated_milp' if int_eval['overall_color_coverage'] > ts_eval['overall_color_coverage'] else '2_step',
                'difference': abs(int_eval['overall_color_coverage'] - ts_eval['overall_color_coverage'])
            },
            'size_coverage': {
                'integrated_milp': int_eval['overall_size_coverage'],
                '2_step': ts_eval['overall_size_coverage'],
                'winner': 'integrated_milp' if int_eval['overall_size_coverage'] > ts_eval['overall_size_coverage'] else '2_step',
                'difference': abs(int_eval['overall_size_coverage'] - ts_eval['overall_size_coverage'])
            },
            'allocation_efficiency': {
                'integrated_milp': int_eval['overall_allocation_efficiency'],
                '2_step': ts_eval['overall_allocation_efficiency'],
                'winner': 'integrated_milp' if int_eval['overall_allocation_efficiency'] > ts_eval['overall_allocation_efficiency'] else '2_step',
                'difference': abs(int_eval['overall_allocation_efficiency'] - ts_eval['overall_allocation_efficiency'])
            },
            'total_score': {
                'integrated_milp': int_eval['total_score'],
                '2_step': ts_eval['total_score'],
                'winner': 'integrated_milp' if int_eval['total_score'] > ts_eval['total_score'] else '2_step',
                'difference': abs(int_eval['total_score'] - ts_eval['total_score'])
            }
        }
    
    def _compare_computational_efficiency(self, integrated_result, two_step_result):
        """ê³„ì‚° íš¨ìœ¨ì„± ë¹„êµ"""
        
        comparison = {
            'total_time': {
                'integrated_milp': integrated_result['total_time'],
                '2_step': two_step_result['total_time'],
                'winner': 'integrated_milp' if integrated_result['total_time'] < two_step_result['total_time'] else '2_step',
                'speedup': max(integrated_result['total_time'], two_step_result['total_time']) / min(integrated_result['total_time'], two_step_result['total_time'])
            }
        }
        
        # 2-Step ë°©ì‹ì˜ ì„¸ë¶€ ì‹œê°„ ë¶„ì„
        if '2_step' in two_step_result['method']:
            step_analysis = two_step_result.get('step_analysis', {})
            comparison['2_step_breakdown'] = {
                'step1_time': step_analysis.get('step1', {}).get('time', 0),
                'step2_time': step_analysis.get('step2', {}).get('time', 0),
                'step1_ratio': step_analysis.get('step1', {}).get('time', 0) / two_step_result['total_time'] if two_step_result['total_time'] > 0 else 0
            }
        
        return comparison
    
    def _compare_coverage(self, integrated_analysis, two_step_analysis):
        """ì»¤ë²„ë¦¬ì§€ ì„±ëŠ¥ ë¹„êµ"""
        
        int_style = integrated_analysis['style_coverage']
        ts_style = two_step_analysis['style_coverage']
        
        return {
            'color_coverage_detail': {
                'integrated_milp': {
                    'avg': int_style['color_coverage']['avg_ratio'],
                    'max': int_style['color_coverage']['max_ratio'],
                    'min': int_style['color_coverage']['min_ratio']
                },
                '2_step': {
                    'avg': ts_style['color_coverage']['avg_ratio'],
                    'max': ts_style['color_coverage']['max_ratio'],
                    'min': ts_style['color_coverage']['min_ratio']
                }
            },
            'size_coverage_detail': {
                'integrated_milp': {
                    'avg': int_style['size_coverage']['avg_ratio'],
                    'max': int_style['size_coverage']['max_ratio'],
                    'min': int_style['size_coverage']['min_ratio']
                },
                '2_step': {
                    'avg': ts_style['size_coverage']['avg_ratio'],
                    'max': ts_style['size_coverage']['max_ratio'],
                    'min': ts_style['size_coverage']['min_ratio']
                }
            }
        }
    
    def _compare_allocation_efficiency(self, integrated_result, two_step_result):
        """ë°°ë¶„ íš¨ìœ¨ì„± ë¹„êµ"""
        
        int_opt = integrated_result['optimization_result']
        ts_opt = two_step_result['optimization_result']
        
        return {
            'allocation_rate': {
                'integrated_milp': int_opt['allocation_rate'],
                '2_step': ts_opt['allocation_rate'],
                'winner': 'integrated_milp' if int_opt['allocation_rate'] > ts_opt['allocation_rate'] else '2_step',
                'difference': abs(int_opt['allocation_rate'] - ts_opt['allocation_rate'])
            },
            'total_allocated': {
                'integrated_milp': int_opt['total_allocated'],
                '2_step': ts_opt['total_allocated'],
                'winner': 'integrated_milp' if int_opt['total_allocated'] > ts_opt['total_allocated'] else '2_step',
                'difference': abs(int_opt['total_allocated'] - ts_opt['total_allocated'])
            },
            'allocated_stores': {
                'integrated_milp': int_opt['allocated_stores'],
                '2_step': ts_opt['allocated_stores'],
                'winner': 'integrated_milp' if int_opt['allocated_stores'] > ts_opt['allocated_stores'] else '2_step',
                'difference': abs(int_opt['allocated_stores'] - ts_opt['allocated_stores'])
            }
        }
    
    def _create_overall_assessment(self, comparison):
        """ì¢…í•© í‰ê°€ ìƒì„±"""
        
        perf_metrics = comparison['performance_metrics']
        comp_eff = comparison['computational_efficiency']
        alloc_eff = comparison['allocation_efficiency']
        
        # ìŠ¹ë¦¬ íšŸìˆ˜ ê³„ì‚°
        integrated_wins = 0
        two_step_wins = 0
        
        for metric in perf_metrics.values():
            if metric['winner'] == 'integrated_milp':
                integrated_wins += 1
            else:
                two_step_wins += 1
        
        for metric in alloc_eff.values():
            if metric['winner'] == 'integrated_milp':
                integrated_wins += 1
            else:
                two_step_wins += 1
        
        # ì‹œê°„ íš¨ìœ¨ì„±
        if comp_eff['total_time']['winner'] == 'integrated_milp':
            integrated_wins += 1
        else:
            two_step_wins += 1
        
        # ì¢…í•© íŒì •
        if integrated_wins > two_step_wins:
            overall_winner = 'integrated_milp'
            strength = 'comprehensive optimization'
        elif two_step_wins > integrated_wins:
            overall_winner = '2_step'
            strength = 'coverage priority and flexibility'
        else:
            overall_winner = 'tie'
            strength = 'context dependent'
        
        return {
            'overall_winner': overall_winner,
            'integrated_wins': integrated_wins,
            '2_step_wins': two_step_wins,
            'key_strength': strength,
            'speedup_factor': comp_eff['total_time']['speedup'],
            'coverage_gap': max(
                perf_metrics['color_coverage']['difference'],
                perf_metrics['size_coverage']['difference']
            ),
            'allocation_gap': alloc_eff['allocation_rate']['difference']
        }
    
    def _print_comparison_results(self, comparison):
        """ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        
        print(f"\nğŸ† ë°©ì‹ë³„ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("="*60)
        
        if 'performance_metrics' not in comparison:
            print("âŒ í•œ ìª½ ì´ìƒì˜ ë°©ì‹ì´ ì‹¤íŒ¨í•˜ì—¬ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        perf = comparison['performance_metrics']
        comp = comparison['computational_efficiency']
        alloc = comparison['allocation_efficiency']
        overall = comparison['overall_assessment']
        
        print(f"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ:")
        print(f"   ìƒ‰ìƒ ì»¤ë²„ë¦¬ì§€: í†µí•© {perf['color_coverage']['integrated_milp']:.3f} vs 2-Step {perf['color_coverage']['2_step']:.3f} ({'ìŠ¹ë¦¬: ' + perf['color_coverage']['winner']})")
        print(f"   ì‚¬ì´ì¦ˆ ì»¤ë²„ë¦¬ì§€: í†µí•© {perf['size_coverage']['integrated_milp']:.3f} vs 2-Step {perf['size_coverage']['2_step']:.3f} ({'ìŠ¹ë¦¬: ' + perf['size_coverage']['winner']})")
        print(f"   ë°°ë¶„ íš¨ìœ¨ì„±: í†µí•© {perf['allocation_efficiency']['integrated_milp']:.4f} vs 2-Step {perf['allocation_efficiency']['2_step']:.4f} ({'ìŠ¹ë¦¬: ' + perf['allocation_efficiency']['winner']})")
        print(f"   ì¢…í•© ì ìˆ˜: í†µí•© {perf['total_score']['integrated_milp']:.3f} vs 2-Step {perf['total_score']['2_step']:.3f} ({'ìŠ¹ë¦¬: ' + perf['total_score']['winner']})")
        
        print(f"\nâ±ï¸ ê³„ì‚° íš¨ìœ¨ì„±:")
        print(f"   ì‹¤í–‰ ì‹œê°„: í†µí•© {comp['total_time']['integrated_milp']:.2f}ì´ˆ vs 2-Step {comp['total_time']['2_step']:.2f}ì´ˆ")
        print(f"   ì†ë„ ìš°ìœ„: {comp['total_time']['winner']} ({comp['total_time']['speedup']:.1f}ë°° ë¹ ë¦„)")
        
        if '2_step_breakdown' in comp:
            breakdown = comp['2_step_breakdown']
            print(f"   2-Step ì„¸ë¶€: Step1 {breakdown['step1_time']:.2f}ì´ˆ ({breakdown['step1_ratio']:.1%}), Step2 {breakdown['step2_time']:.2f}ì´ˆ")
        
        print(f"\nğŸ“¦ ë°°ë¶„ ì„±ê³¼:")
        print(f"   ë°°ë¶„ë¥ : í†µí•© {alloc['allocation_rate']['integrated_milp']:.1%} vs 2-Step {alloc['allocation_rate']['2_step']:.1%} ({'ìŠ¹ë¦¬: ' + alloc['allocation_rate']['winner']})")
        print(f"   ì´ ë°°ë¶„ëŸ‰: í†µí•© {alloc['total_allocated']['integrated_milp']:,}ê°œ vs 2-Step {alloc['total_allocated']['2_step']:,}ê°œ")
        print(f"   ë°°ë¶„ ë§¤ì¥ìˆ˜: í†µí•© {alloc['allocated_stores']['integrated_milp']}ê°œ vs 2-Step {alloc['allocated_stores']['2_step']}ê°œ")
        
        print(f"\nğŸ† ì¢…í•© í‰ê°€:")
        print(f"   ì „ì²´ ìŠ¹ì: {overall['overall_winner']}")
        print(f"   ìŠ¹ë¦¬ ì ìˆ˜: í†µí•© MILP {overall['integrated_wins']}ìŠ¹ vs 2-Step {overall['2_step_wins']}ìŠ¹")
        print(f"   í•µì‹¬ ê°•ì : {overall['key_strength']}")
        print(f"   ì†ë„ ì°¨ì´: {overall['speedup_factor']:.1f}ë°°")
        print(f"   ì»¤ë²„ë¦¬ì§€ ê²©ì°¨: ìµœëŒ€ {overall['coverage_gap']:.3f}")
        print(f"   ë°°ë¶„ë¥  ê²©ì°¨: {overall['allocation_gap']:.1%}")
        
        # ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        if overall['overall_winner'] == 'integrated_milp':
            print(f"   âœ… í†µí•© MILP ë°©ì‹ ê¶Œì¥")
            print(f"   - ì¢…í•©ì  ìµœì í™” ì„±ëŠ¥ ìš°ìˆ˜")
            print(f"   - ìˆ˜í•™ì  ìµœì ì„± ë³´ì¥")
        elif overall['overall_winner'] == '2_step':
            print(f"   âœ… 2-Step ë°©ì‹ ê¶Œì¥")
            print(f"   - ì»¤ë²„ë¦¬ì§€ ìš°ì„ ìˆœìœ„ ëª…í™•")
            print(f"   - ìœ ì—°í•œ ë£° ì ìš© ê°€ëŠ¥")
        else:
            print(f"   âš–ï¸ ìƒí™©ì— ë”°ë¥¸ ì„ íƒ ê¶Œì¥")
            print(f"   - ì»¤ë²„ë¦¬ì§€ ì ˆëŒ€ ìš°ì„ : 2-Step")
            print(f"   - ë³µí•© ìµœì í™” í•„ìš”: í†µí•© MILP")


if __name__ == "__main__":
    # ë¹„êµ ì‹¤í—˜ ì‹¤í–‰
    experiment = MethodComparisonExperiment()
    
    print("ğŸš€ 2-Step vs í†µí•© MILP ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜")
    print("="*50)
    
    # ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë¹„êµ
    scenarios_to_test = ['baseline', 'balance_focused', 'equity_focused']
    
    for scenario in scenarios_to_test:
        print(f"\n{'='*70}")
        print(f"ì‹œë‚˜ë¦¬ì˜¤: {scenario}")
        print(f"{'='*70}")
        
        try:
            comparison_result = experiment.compare_methods(scenario)
            # í•„ìš”í•˜ë©´ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            
        except Exception as e:
            print(f"âŒ {scenario} ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í—˜ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"\nğŸ‰ ëª¨ë“  ë¹„êµ ì‹¤í—˜ ì™„ë£Œ!") 